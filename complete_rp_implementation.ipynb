{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Team-06**\n",
        "\n",
        "#Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model(Research Paper Implementation)\n",
        "---\n",
        "\n",
        "\n",
        "**Vrishmi Parikh (202318013)**\n",
        "\n",
        "**Mahmood Topiwala (202318030)**\n",
        "\n",
        "**Anurag Shukla (202318039)**\n",
        "\n",
        "**Tanaz Pathan (202318056)**\n"
      ],
      "metadata": {
        "id": "UJfhXGS1-NQG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TDrGUcZ8oam"
      },
      "source": [
        "**Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dbTADniu_dJ"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "# Open the .tar.gz file\n",
        "tar_ref = tarfile.open('/content/drive/MyDrive/nf_prize_dataset.tar.gz', 'r:gz')\n",
        "\n",
        "# Extract all contents to a specified directory\n",
        "tar_ref.extractall('/content')\n",
        "\n",
        "# Close the file\n",
        "tar_ref.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AST6YHvxvzrO"
      },
      "outputs": [],
      "source": [
        "path = \"/content\"\n",
        "\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_sparse_correlation_matrix(A):\n",
        "    scaler = StandardScaler(with_mean=False)\n",
        "    scaled_A = scaler.fit_transform(A)  # Assuming A is a CSR or CSC matrix\n",
        "    corr_matrix = (1/scaled_A.shape[0]) * (scaled_A.T @ scaled_A)\n",
        "    return corr_matrix\n",
        "\n",
        "def pre_processing(mat, mat_file):\n",
        "    # Create bu and bi indexes\n",
        "    # bi_index is a list with a size equal to the number of users\n",
        "    #    the jth element is a list storing the indexes of movies rated by user j\n",
        "    # bu_index is the same but storing the indexes of users whose rating is\n",
        "    #    available for a movie\n",
        "    # These indexes will help to the algorithms computation\n",
        "\n",
        "    shape = str(mat.shape[0])+\"_\"+str(mat.shape[1])\n",
        "    bu_index_file = mat_file+\"_bu_index_\"+shape+\".data\"\n",
        "    bi_index_file = mat_file+\"_bi_index_\"+shape+\".data\"\n",
        "\n",
        "    if not (os.path.isfile(bu_index_file) and os.path.isfile(bi_index_file)):\n",
        "        #mat = io.loadmat(mat_file)['X']\n",
        "        \"\"\"mat = mat[1:5000,1:5000]\n",
        "        mat = mat[mat.getnnz(1)>0][:,mat.getnnz(0)>0]\"\"\"\n",
        "\n",
        "        print(\"Pre-processing...\")\n",
        "        mat_nonzero = mat.nonzero()\n",
        "        \"\"\"cx = mat.tocoo()\n",
        "        bi_index = [[]]*mat.shape[0]\n",
        "        bu_index = [[]]*mat.shape[1]\n",
        "        for i,j,v in zip(cx.row, cx.col, cx.data):\n",
        "          bi_index[i].append(j)\n",
        "          bu_index[j].append(i)\n",
        "        print(bi_index[0])\"\"\"\n",
        "\n",
        "        print(\"   make bi indexes...\")\n",
        "        bi_index = []\n",
        "        for k, g in groupby(zip(mat_nonzero[0], mat_nonzero[1]), itemgetter(0)):\n",
        "          to_add = list(map(lambda x:int(x[1]), list(g)))\n",
        "          bi_index.append(to_add)\n",
        "\n",
        "        print(\"   make bu indexes...\")\n",
        "        bu_index = []\n",
        "        indexes = np.argsort(mat_nonzero[1])\n",
        "        for k, g in groupby(zip(mat_nonzero[1][indexes], mat_nonzero[0][indexes]), itemgetter(0)):\n",
        "          to_add = list(map(lambda x:int(x[1]), list(g)))\n",
        "          bu_index.append(to_add)\n",
        "\n",
        "        with open(bi_index_file, \"wb\") as fp:\n",
        "            pickle.dump(bi_index, fp)\n",
        "        with open(bu_index_file, \"wb\") as fp:\n",
        "            pickle.dump(bu_index, fp)\n",
        "    else:\n",
        "        with open(bi_index_file, \"rb\") as fp:\n",
        "            bi_index = pickle.load(fp)\n",
        "        with open(bu_index_file, \"rb\") as fp:\n",
        "            bu_index = pickle.load(fp)\n",
        "\n",
        "    print(\"Pre-processing done.\")\n",
        "    return bu_index, bi_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wfmmltl8hvj"
      },
      "source": [
        "**Data Compilation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG7SjFW_wEnM",
        "outputId": "bcca4957-932b-4d48-90b7-16d7364e838d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100  /  17771\n",
            "200  /  17771\n",
            "300  /  17771\n",
            "400  /  17771\n",
            "500  /  17771\n",
            "600  /  17771\n",
            "700  /  17771\n",
            "800  /  17771\n",
            "900  /  17771\n",
            "1000  /  17771\n",
            "1100  /  17771\n",
            "1200  /  17771\n",
            "1300  /  17771\n",
            "1400  /  17771\n",
            "1500  /  17771\n",
            "1600  /  17771\n",
            "1700  /  17771\n",
            "1800  /  17771\n",
            "1900  /  17771\n",
            "2000  /  17771\n",
            "2100  /  17771\n",
            "2200  /  17771\n",
            "2300  /  17771\n",
            "2400  /  17771\n",
            "2500  /  17771\n",
            "2600  /  17771\n",
            "2700  /  17771\n",
            "2800  /  17771\n",
            "2900  /  17771\n",
            "3000  /  17771\n",
            "3100  /  17771\n",
            "3200  /  17771\n",
            "3300  /  17771\n",
            "3400  /  17771\n",
            "3500  /  17771\n",
            "3600  /  17771\n",
            "3700  /  17771\n",
            "3800  /  17771\n",
            "3900  /  17771\n",
            "4000  /  17771\n",
            "4100  /  17771\n",
            "4200  /  17771\n",
            "4300  /  17771\n",
            "4400  /  17771\n",
            "4500  /  17771\n",
            "4600  /  17771\n",
            "4700  /  17771\n",
            "4800  /  17771\n",
            "4900  /  17771\n",
            "5000  /  17771\n",
            "5100  /  17771\n",
            "5200  /  17771\n",
            "5300  /  17771\n",
            "5400  /  17771\n",
            "5500  /  17771\n",
            "5600  /  17771\n",
            "5700  /  17771\n",
            "5800  /  17771\n",
            "5900  /  17771\n",
            "6000  /  17771\n",
            "6100  /  17771\n",
            "6200  /  17771\n",
            "6300  /  17771\n",
            "6400  /  17771\n",
            "6500  /  17771\n",
            "6600  /  17771\n",
            "6700  /  17771\n",
            "6800  /  17771\n",
            "6900  /  17771\n",
            "7000  /  17771\n",
            "7100  /  17771\n",
            "7200  /  17771\n",
            "7300  /  17771\n",
            "7400  /  17771\n",
            "7500  /  17771\n",
            "7600  /  17771\n",
            "7700  /  17771\n",
            "7800  /  17771\n",
            "7900  /  17771\n",
            "8000  /  17771\n",
            "8100  /  17771\n",
            "8200  /  17771\n",
            "8300  /  17771\n",
            "8400  /  17771\n",
            "8500  /  17771\n",
            "8600  /  17771\n",
            "8700  /  17771\n",
            "8800  /  17771\n",
            "8900  /  17771\n",
            "9000  /  17771\n",
            "9100  /  17771\n",
            "9200  /  17771\n",
            "9300  /  17771\n",
            "9400  /  17771\n",
            "9500  /  17771\n",
            "9600  /  17771\n",
            "9700  /  17771\n",
            "9800  /  17771\n",
            "9900  /  17771\n",
            "10000  /  17771\n",
            "10100  /  17771\n",
            "10200  /  17771\n",
            "10300  /  17771\n",
            "10400  /  17771\n",
            "10500  /  17771\n",
            "10600  /  17771\n",
            "10700  /  17771\n",
            "10800  /  17771\n",
            "10900  /  17771\n",
            "11000  /  17771\n",
            "11100  /  17771\n",
            "11200  /  17771\n",
            "11300  /  17771\n",
            "11400  /  17771\n",
            "11500  /  17771\n",
            "11600  /  17771\n",
            "11700  /  17771\n",
            "11800  /  17771\n",
            "11900  /  17771\n",
            "12000  /  17771\n",
            "12100  /  17771\n",
            "12200  /  17771\n",
            "12300  /  17771\n",
            "12400  /  17771\n",
            "12500  /  17771\n",
            "12600  /  17771\n",
            "12700  /  17771\n",
            "12800  /  17771\n",
            "12900  /  17771\n",
            "13000  /  17771\n",
            "13100  /  17771\n",
            "13200  /  17771\n",
            "13300  /  17771\n",
            "13400  /  17771\n",
            "13500  /  17771\n",
            "13600  /  17771\n",
            "13700  /  17771\n",
            "13800  /  17771\n",
            "13900  /  17771\n",
            "14000  /  17771\n",
            "14100  /  17771\n",
            "14200  /  17771\n",
            "14300  /  17771\n",
            "14400  /  17771\n",
            "14500  /  17771\n",
            "14600  /  17771\n",
            "14700  /  17771\n",
            "14800  /  17771\n",
            "14900  /  17771\n",
            "15000  /  17771\n",
            "15100  /  17771\n",
            "15200  /  17771\n",
            "15300  /  17771\n",
            "15400  /  17771\n",
            "15500  /  17771\n",
            "15600  /  17771\n",
            "15700  /  17771\n",
            "15800  /  17771\n",
            "15900  /  17771\n",
            "16000  /  17771\n",
            "16100  /  17771\n",
            "16200  /  17771\n",
            "16300  /  17771\n",
            "16400  /  17771\n",
            "16500  /  17771\n",
            "16600  /  17771\n",
            "16700  /  17771\n",
            "16800  /  17771\n",
            "16900  /  17771\n",
            "17000  /  17771\n",
            "17100  /  17771\n",
            "17200  /  17771\n",
            "17300  /  17771\n",
            "17400  /  17771\n",
            "17500  /  17771\n",
            "17600  /  17771\n",
            "17700  /  17771\n"
          ]
        }
      ],
      "source": [
        "import sys  # Importing the sys module for system-specific parameters and functions\n",
        "import os  # Importing the os module for interacting with the operating system\n",
        "from scipy.sparse import dok_matrix, csr_matrix, lil_matrix  # Importing specific sparse matrix types from SciPy\n",
        "from scipy import io  # Importing input/output functions from SciPy\n",
        "import tarfile  # Importing the tarfile module to manipulate tar archives\n",
        "import numpy as np  # Importing the numpy library for numerical computing\n",
        "\n",
        "\n",
        "#################################################\n",
        "total_no_users = 2649429  # Total number of users in the dataset\n",
        "total_no_movies = 17770  # Total number of movies in the dataset\n",
        "\n",
        "def process_content(content, D):\n",
        "    \"\"\"\n",
        "    Process the content of a file and update the sparse matrix D.\n",
        "\n",
        "    Args:\n",
        "    content (str): The content of the file.\n",
        "    D (scipy.sparse.lil_matrix): The sparse matrix to update.\n",
        "\n",
        "    Returns:\n",
        "    scipy.sparse.lil_matrix: The updated sparse matrix.\n",
        "    \"\"\"\n",
        "    lines = content.split(\"\\n\")  # Splitting the content into lines\n",
        "    id_movie = int(lines[0][:-1]) - 1  # Extracting the movie ID\n",
        "    for i in range(1, len(lines)):\n",
        "        if lines[i] != '':\n",
        "            line = lines[i].split(\",\")\n",
        "            id_user = int(line[0]) - 1  # Extracting the user ID\n",
        "            rating = int(line[1])  # Extracting the rating\n",
        "            D[id_user, id_movie] = rating  # Updating the matrix with the rating\n",
        "    return D\n",
        "\n",
        "\n",
        "def rating_compiler(folder_name, out_path):\n",
        "    \"\"\"\n",
        "    Compile ratings from individual files in a folder into a single sparse matrix.\n",
        "\n",
        "    Args:\n",
        "    folder_name (str): Path to the folder containing individual rating files.\n",
        "    out_path (str): Output path for the compiled sparse matrix.\n",
        "    \"\"\"\n",
        "    D = lil_matrix((total_no_users, total_no_movies), dtype=np.uint8)  # Initialize a sparse matrix\n",
        "    res_listdir = os.listdir(folder_name)  # Get the list of files in the folder\n",
        "    number = len(res_listdir)  # Get the total number of files\n",
        "    i = 0\n",
        "    for f in res_listdir:\n",
        "        if os.path.isfile(folder_name+f):\n",
        "            if i % 100 == 0:\n",
        "                print(i, \" / \", number)\n",
        "            myfile = open(folder_name+f)\n",
        "            content = myfile.read()\n",
        "            myfile.close()\n",
        "            D = process_content(content, D)  # Process the content of each file and update the matrix\n",
        "        i += 1\n",
        "    D = csr_matrix(D)  # Convert the matrix to Compressed Sparse Row format\n",
        "    io.savemat(out_path, {'X': D})  # Save the matrix to a .mat file\n",
        "\n",
        "\n",
        "def rating_compiler2(tar_name, out_path):\n",
        "    \"\"\"\n",
        "    Compile ratings from individual files in a tar archive into a single sparse matrix.\n",
        "\n",
        "    Args:\n",
        "    tar_name (str): Path to the tar archive.\n",
        "    out_path (str): Output path for the compiled sparse matrix.\n",
        "    \"\"\"\n",
        "    D = lil_matrix((total_no_users, total_no_movies), dtype=np.uint8)  # Initialize a sparse matrix\n",
        "    tar = tarfile.open(tar_name)  # Open the tar archive\n",
        "    res_getmembers = tar.getmembers()  # Get the list of members (files) in the archive\n",
        "    number = len(res_getmembers)  # Get the total number of members\n",
        "    i = 0\n",
        "    for member in res_getmembers:\n",
        "        f = tar.extractfile(member)  # Extract the file from the archive\n",
        "        if f is not None:\n",
        "            if i % 100 == 0:\n",
        "                print(i, \" / \", number)\n",
        "            content = f.read()\n",
        "            f.close()\n",
        "            D = process_content(content.decode(), D)  # Process the content of each file and update the matrix\n",
        "        i += 1\n",
        "    tar.close()  # Close the tar archive\n",
        "    D = csr_matrix(D, dtype=np.float64)  # Convert the matrix to Compressed Sparse Row format\n",
        "    io.savemat(out_path, {'X': D})  # Save the matrix to a .mat file\n",
        "\n",
        "\n",
        "def extract_T_and_R(D_file_name, file_name, out_T_path, out_R_path):\n",
        "    \"\"\"\n",
        "    Extract matrices T and R from the full dataset matrix D based on a list of selected users and movies.\n",
        "\n",
        "    Args:\n",
        "    D_file_name (str): Path to the full dataset matrix file.\n",
        "    file_name (str): Path to the file containing the list of selected users and movies.\n",
        "    out_T_path (str): Output path for the matrix T.\n",
        "    out_R_path (str): Output path for the matrix R.\n",
        "    \"\"\"\n",
        "    D = io.loadmat(D_file_name)['X']  # Load the full dataset matrix\n",
        "    myfile = open(file_name)\n",
        "    content = myfile.read()\n",
        "    myfile.close()\n",
        "    lines = content.split(\"\\n\")  # Split the content into lines\n",
        "    users, movies = set(), set()\n",
        "    for line in lines:\n",
        "        if line != '':\n",
        "            line_split = line.split(\":\")\n",
        "            if len(line_split) == 2:\n",
        "                # Movie id\n",
        "                movies.add(int(line_split[0]) - 1)  # Add the movie ID to the set\n",
        "            else:\n",
        "                # User id\n",
        "                users.add(int(line_split[0]) - 1)  # Add the user ID to the set\n",
        "    T = D[list(users), :]  # Extract matrix T based on selected users\n",
        "    T = T[:, list(movies)]  # Extract matrix T based on selected movies\n",
        "    io.savemat(out_T_path, {'X': T})  # Save matrix T to a .mat file\n",
        "\n",
        "    movies2 = set(range(total_no_movies))\n",
        "    movies2 = movies2.difference(movies)  # Get the set difference to find movies not selected\n",
        "    users2 = set(range(total_no_users))\n",
        "    users2 = users2.difference(users)  # Get the set difference to find users not selected\n",
        "\n",
        "    R = D[list(users2), :]  # Extract matrix R based on unselected users\n",
        "    R = R[:, list(movies2)]  # Extract matrix R based on unselected movies\n",
        "    io.savemat(out_R_path, {'X': R})  # Save matrix R to a .mat file\n",
        "\n",
        "\n",
        "#################################################\n",
        "if __name__ == \"__main__\":\n",
        "    rating_compiler2(path+\"/download/training_set.tar\", path+\"/D.mat\")\n",
        "    #extract_T_and_R(path+\"/D.mat\", path+\"/download/qualifying.txt\", path+\"/T.mat\", path+\"/R.mat\")\n",
        "    extract_T_and_R(path+\"/D.mat\", path+\"/download/probe.txt\", path+\"/T.mat\", path+\"/R.mat\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import io\n",
        "\n",
        "# Load the T.mat file\n",
        "data_D = io.loadmat('D.mat')\n",
        "\n",
        "# Extract the matrix from the loaded data\n",
        "matrix = data_D['X']\n",
        "\n",
        "# Convert the matrix to a pandas DataFrame\n",
        "df = pd.DataFrame.sparse.from_spmatrix(matrix)\n",
        "\n",
        "# Display the DataFrame\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7sVr2AS5fjYz",
        "outputId": "332300c9-45dd-48fd-95c9-8369d8a8024b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0      1      2      3      4      5      6      7      8      9      \\\n",
              "0          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "1          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "3          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "4          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "2649424    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2649425    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2649426    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2649427    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2649428    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "         ...  17760  17761  17762  17763  17764  17765  17766  17767  17768  \\\n",
              "0        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "1        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "3        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "4        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "2649424  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2649425  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2649426  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2649427  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2649428  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "         17769  \n",
              "0          0.0  \n",
              "1          0.0  \n",
              "2          0.0  \n",
              "3          0.0  \n",
              "4          0.0  \n",
              "...        ...  \n",
              "2649424    0.0  \n",
              "2649425    0.0  \n",
              "2649426    0.0  \n",
              "2649427    0.0  \n",
              "2649428    0.0  \n",
              "\n",
              "[2649429 rows x 17770 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-145b8c13-240e-48c7-ac46-211d64625a94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>17760</th>\n",
              "      <th>17761</th>\n",
              "      <th>17762</th>\n",
              "      <th>17763</th>\n",
              "      <th>17764</th>\n",
              "      <th>17765</th>\n",
              "      <th>17766</th>\n",
              "      <th>17767</th>\n",
              "      <th>17768</th>\n",
              "      <th>17769</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2649424</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2649425</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2649426</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2649427</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2649428</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2649429 rows Ã— 17770 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-145b8c13-240e-48c7-ac46-211d64625a94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-145b8c13-240e-48c7-ac46-211d64625a94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-145b8c13-240e-48c7-ac46-211d64625a94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a9695cbc-3217-418e-a858-cb1a3982d222\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9695cbc-3217-418e-a858-cb1a3982d222')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a9695cbc-3217-418e-a858-cb1a3982d222 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_31bcb244-db62-46d3-9007-d070f169b0a9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_31bcb244-db62-46d3-9007-d070f169b0a9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import io\n",
        "\n",
        "# Load the T.mat file\n",
        "data = io.loadmat('T.mat')\n",
        "\n",
        "# Extract the matrix from the loaded data\n",
        "matrix = data['X']\n",
        "\n",
        "# Convert the matrix to a pandas DataFrame\n",
        "df = pd.DataFrame.sparse.from_spmatrix(matrix)\n",
        "\n",
        "# Display the DataFrame\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_odzHi5BZMnH",
        "outputId": "d162a1a8-7e99-4845-90d8-2d2a928a03e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0      1      2      3      4      5      6      7      8      9      \\\n",
              "0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "3         0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0   \n",
              "4         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "462853    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "462854    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "462855    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "462856    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "462857    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "        ...  16928  16929  16930  16931  16932  16933  16934  16935  16936  \\\n",
              "0       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "1       ...    0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    4.0   \n",
              "2       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "3       ...    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0   \n",
              "4       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "462853  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "462854  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "462855  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "462856  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "462857  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "        16937  \n",
              "0         0.0  \n",
              "1         0.0  \n",
              "2         0.0  \n",
              "3         0.0  \n",
              "4         0.0  \n",
              "...       ...  \n",
              "462853    0.0  \n",
              "462854    0.0  \n",
              "462855    0.0  \n",
              "462856    0.0  \n",
              "462857    0.0  \n",
              "\n",
              "[462858 rows x 16938 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2443613-2fc0-4d18-b268-4a562bccf90a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>16928</th>\n",
              "      <th>16929</th>\n",
              "      <th>16930</th>\n",
              "      <th>16931</th>\n",
              "      <th>16932</th>\n",
              "      <th>16933</th>\n",
              "      <th>16934</th>\n",
              "      <th>16935</th>\n",
              "      <th>16936</th>\n",
              "      <th>16937</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462853</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462854</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462855</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462856</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462857</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>462858 rows Ã— 16938 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2443613-2fc0-4d18-b268-4a562bccf90a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2443613-2fc0-4d18-b268-4a562bccf90a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2443613-2fc0-4d18-b268-4a562bccf90a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24882c13-4197-42e8-ad21-fdae92778ba6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24882c13-4197-42e8-ad21-fdae92778ba6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24882c13-4197-42e8-ad21-fdae92778ba6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_10932b9c-c88d-438d-8d42-6bf46bc4401b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_10932b9c-c88d-438d-8d42-6bf46bc4401b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eGOCqYzZg0E",
        "outputId": "6b014594-1a56-456a-d004-cdb96f682bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "16933    0\n",
              "16934    0\n",
              "16935    0\n",
              "16936    0\n",
              "16937    0\n",
              "Length: 16938, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import io\n",
        "\n",
        "# Load the T.mat file\n",
        "data_R = io.loadmat('R.mat')\n",
        "\n",
        "# Extract the matrix from the loaded data\n",
        "matrix = data_R['X']\n",
        "\n",
        "# Convert the matrix to a pandas DataFrame\n",
        "R_df = pd.DataFrame.sparse.from_spmatrix(matrix)\n",
        "\n",
        "# Display the DataFrame\n",
        "\n",
        "R_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "TOZWRUzRV8I7",
        "outputId": "561bb2b4-2fb4-41d1-843e-97a624c30e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0    1    2    3    4    5    6    7    8    9    ...  822  823  824  \\\n",
              "0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "2186566  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2186567  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2186568  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2186569  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2186570  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "\n",
              "         825  826  827  828  829  830  831  \n",
              "0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "...      ...  ...  ...  ...  ...  ...  ...  \n",
              "2186566  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2186567  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2186568  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2186569  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2186570  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[2186571 rows x 832 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-132d8d09-9d79-45a7-ba3b-ec41cd516b19\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>822</th>\n",
              "      <th>823</th>\n",
              "      <th>824</th>\n",
              "      <th>825</th>\n",
              "      <th>826</th>\n",
              "      <th>827</th>\n",
              "      <th>828</th>\n",
              "      <th>829</th>\n",
              "      <th>830</th>\n",
              "      <th>831</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2186566</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2186567</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2186568</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2186569</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2186570</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2186571 rows Ã— 832 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-132d8d09-9d79-45a7-ba3b-ec41cd516b19')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-132d8d09-9d79-45a7-ba3b-ec41cd516b19 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-132d8d09-9d79-45a7-ba3b-ec41cd516b19');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22d9d1dc-8450-414d-8b2b-ab07359ded99\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22d9d1dc-8450-414d-8b2b-ab07359ded99')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22d9d1dc-8450-414d-8b2b-ab07359ded99 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_207faacf-a4ce-464c-a1a2-6a91fb5f5985\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('R_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_207faacf-a4ce-464c-a1a2-6a91fb5f5985 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('R_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "R_df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Check if user with ID 133 has rated any movies\n",
        "if df.loc[133].sum() > 0:\n",
        "    print(\"User 133 has rated movies.\")\n",
        "else:\n",
        "    print(\"User 133 has not rated any movies.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAn5CAhrfwgt",
        "outputId": "0ec9509a-a035-4ff9-ad9b-a37c8cba52b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User 133 has rated movies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get the ratings for user 133\n",
        "user_133_ratings = df.loc[133]\n",
        "\n",
        "# Find the indices (movie IDs) where the user has rated\n",
        "rated_movies_indices = user_133_ratings[user_133_ratings > 0].index\n",
        "\n",
        "# Print the movies that user 133 has rated\n",
        "print(\"Movies rated by user 133:\")\n",
        "print(rated_movies_indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK8-Ab0hiXZM",
        "outputId": "89c1e351-660f-45fe-e0f9-5736677e35b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movies rated by user 133:\n",
            "Index([   27,    54,    57,    76,   117,   142,   147,   190,   269,   272,\n",
            "       ...\n",
            "       17498, 17507, 17512, 17557, 17559, 17588, 17620, 17624, 17702, 17761],\n",
            "      dtype='int64', length=737)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_133_ratings = df.loc[133, 76]\n",
        "\n",
        "# Print the ratings\n",
        "print(\"Ratings of user 133 for the movie:\")\n",
        "print(user_133_ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_Cl-M9wia65",
        "outputId": "40292965-08a2-49e8-8e3c-b243bdb53608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings of user 133 for the movie:\n",
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKb8KRZW8Ywi"
      },
      "source": [
        "**1. Baseline Estimates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2z4FU7X0t_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb8391f-f848-473c-9b77-750801b39042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 111)\n",
            "Pre-processing...\n",
            "   make bi indexes...\n",
            "   make bu indexes...\n",
            "Pre-processing done.\n",
            "Train...\n",
            "compute loss...\n",
            "(6795.411025144216, 6806.739570722432)\n",
            "compute loss...\n",
            "(6690.852175881218, 6702.175321348293)\n",
            "compute loss...\n",
            "(6594.25853430532, 6605.5764553957715)\n",
            "compute loss...\n",
            "(6504.960006596772, 6516.272864673211)\n",
            "compute loss...\n",
            "(6422.3439790573775, 6433.651922357002)\n",
            "compute loss...\n",
            "(6345.8503637638805, 6357.153528536447)\n",
            "compute loss...\n",
            "(6274.967071799976, 6286.26558334668)\n",
            "compute loss...\n",
            "(6209.225877151903, 6220.519850773774)\n",
            "compute loss...\n",
            "(6148.1986375399165, 6159.488179403589)\n",
            "compute loss...\n",
            "(6091.493841370171, 6102.779049298205)\n",
            "compute loss...\n",
            "(6038.753452652229, 6050.034416844546)\n",
            "compute loss...\n",
            "(5989.650028158421, 6000.926831850846)\n",
            "compute loss...\n",
            "(5943.8840833223585, 5955.156803387722)\n",
            "compute loss...\n",
            "(5901.181685403174, 5912.450392899991)\n",
            "compute loss...\n",
            "(5861.292254296137, 5872.557014969412)\n",
            "compute loss...\n",
            "(5823.986553064273, 5835.247427802597)\n",
            "compute loss...\n",
            "(5789.054851813336, 5800.311897066088)\n",
            "compute loss...\n",
            "(5756.305249946521, 5767.558518104644)\n",
            "compute loss...\n",
            "(5725.562143127301, 5736.811682870827)\n",
            "compute loss...\n",
            "(5696.664822459177, 5707.910679074401)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from scipy import io, sparse\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "def compute_loss(mat, mu, bu, bi, l_reg=0.02):\n",
        "  loss = 0\n",
        "\n",
        "  no_users_entries = np.array((mat != 0).sum(1)).T.ravel()\n",
        "  bu_rep = np.repeat(bu.ravel(), no_users_entries)\n",
        "\n",
        "  no_movies_entries = np.array((mat != 0).sum(0)).ravel()\n",
        "  bi_rep = np.repeat(bi.ravel(), no_movies_entries)\n",
        "\n",
        "  temp_mat = sparse.csc_matrix(mat).copy()\n",
        "  temp_mat.data[:] -= bi_rep\n",
        "  temp_mat.data[:] -= mu\n",
        "  temp_mat = sparse.coo_matrix(temp_mat)\n",
        "  temp_mat = sparse.csr_matrix(temp_mat)\n",
        "  temp_mat.data[:] -= bu_rep\n",
        "\n",
        "  loss = (temp_mat.data[:] ** 2).sum()\n",
        "\n",
        "  loss_reg = l_reg * ((bu**2).sum() + (bi**2).sum())\n",
        "  #loss += loss_reg\n",
        "\n",
        "  return loss, loss+loss_reg\n",
        "\n",
        "def baseline_estimator(mat, mat_file, l_reg=0.02, learning_rate=0.0000025):\n",
        "  # subsample the matrix to make computation faster\n",
        "  mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "  mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "  print(mat.shape)\n",
        "  no_users = mat.shape[0]\n",
        "  no_movies = mat.shape[1]\n",
        "\n",
        "  bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "  bu = np.random.rand(no_users,1)  * 2 - 1\n",
        "  bi = np.random.rand(1,no_movies) * 2 - 1\n",
        "  #bu = np.zeros((no_users,1))\n",
        "  #bi = np.zeros((1,no_movies))\n",
        "\n",
        "  mu = mat.data[:].mean()\n",
        "  mat_sum1 = mat.sum(1)\n",
        "  mat_sum0 = mat.sum(0)\n",
        "  n = mat.data[:].shape[0]\n",
        "  no_users_entries = np.array((mat != 0).sum(1))\n",
        "  no_movies_entries = np.array((mat != 0).sum(0))\n",
        "\n",
        "  # Train\n",
        "  print(\"Train...\")\n",
        "  n_iter = 200\n",
        "  for it in range(n_iter):\n",
        "\n",
        "    #bi_sum = bi[bi_index].sum(1).reshape((no_users,1))\n",
        "    #bu_sum = bu.ravel()[bu_index].sum(0).reshape((1,no_movies))\n",
        "\n",
        "    bi_sum = np.array(list(map(lambda x:bi.ravel()[x].sum(), bi_index))).reshape((no_users,1))\n",
        "    bu_sum = np.array(list(map(lambda x:bu.ravel()[x].sum(), bu_index))).reshape((1,no_movies))\n",
        "\n",
        "    # Vectorized operations\n",
        "    bu_gradient = - 2.0 * (mat_sum1 - no_users_entries  * mu - no_users_entries  * bu - bi_sum) + 2.0 * l_reg * bu\n",
        "    bu -= learning_rate * bu_gradient\n",
        "\n",
        "    bi_gradient = - 2.0 * (mat_sum0 - no_movies_entries * mu - no_movies_entries * bi - bu_sum) + 2.0 * l_reg * bi\n",
        "    bi -= learning_rate * bi_gradient\n",
        "\n",
        "    if it % 10 == 0:\n",
        "      print(\"compute loss...\")\n",
        "      print(compute_loss(mat, mu, bu, bi, l_reg=l_reg))\n",
        "\n",
        "  return bu, bi\n",
        "#################################################\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mat_file = path+\"/T.mat\"\n",
        "    mat = io.loadmat(mat_file)['X']\n",
        "    baseline_estimator(mat, mat_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_predicted_ratings(bu, bi, mu):\n",
        "    # Reshape bu and bi to match each other's shapes\n",
        "    bu = np.tile(bu, (1, bi.shape[1]))\n",
        "    bi = np.tile(bi, (bu.shape[0], 1))\n",
        "\n",
        "    # Compute the predicted ratings\n",
        "    predicted_ratings = mu + bu + bi\n",
        "\n",
        "    # Clip predicted ratings to [1, 5] range\n",
        "    predicted_ratings = np.clip(predicted_ratings, 1, 5)\n",
        "\n",
        "    return predicted_ratings\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mat_file = path+\"/T.mat\"\n",
        "    mat = io.loadmat(mat_file)['X']\n",
        "    bu, bi = baseline_estimator(mat, mat_file)\n",
        "\n",
        "    # Compute the global mean\n",
        "    mu = mat.data.mean()\n",
        "\n",
        "    # Compute predicted ratings\n",
        "    predicted_ratings = compute_predicted_ratings(bu, bi, mu)\n",
        "\n",
        "    # Print the shape of predicted ratings\n",
        "    print(\"Shape of predicted ratings:\", predicted_ratings.shape)\n",
        "\n",
        "    # Print the predicted ratings\n",
        "    print(\"Predicted ratings:\")\n",
        "    print(predicted_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edTxo9lub2AQ",
        "outputId": "b2fcacbb-09f6-4975-b4c4-7f3e88c8ff88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 111)\n",
            "Pre-processing done.\n",
            "Train...\n",
            "compute loss...\n",
            "(6385.625087921193, 6396.478812017747)\n",
            "compute loss...\n",
            "(6355.461884660853, 6366.310898756282)\n",
            "compute loss...\n",
            "(6325.940887566455, 6336.785242690217)\n",
            "compute loss...\n",
            "(6297.044160781348, 6307.883906729213)\n",
            "compute loss...\n",
            "(6268.754447046634, 6279.589632417584)\n",
            "compute loss...\n",
            "(6241.055130705574, 6251.885802937279)\n",
            "compute loss...\n",
            "(6213.93020334828, 6224.75640875121)\n",
            "compute loss...\n",
            "(6187.364231883197, 6198.186015673461)\n",
            "compute loss...\n",
            "(6161.342328839911, 6172.15973517087)\n",
            "compute loss...\n",
            "(6135.850124724364, 6146.663196717091)\n",
            "compute loss...\n",
            "(6110.873742262613, 6121.682522035259)\n",
            "compute loss...\n",
            "(6086.399772383067, 6097.204301079185)\n",
            "compute loss...\n",
            "(6062.415251799768, 6073.215569615633)\n",
            "compute loss...\n",
            "(6038.907642070794, 6049.703788281795)\n",
            "compute loss...\n",
            "(6015.86481001643, 6026.656823002544)\n",
            "compute loss...\n",
            "(5993.275009391378, 6004.062926661799)\n",
            "compute loss...\n",
            "(5971.126863714104, 5981.910721931037)\n",
            "compute loss...\n",
            "(5949.409350164489, 5960.189185166175)\n",
            "compute loss...\n",
            "(5928.111784468347, 5938.887631291323)\n",
            "compute loss...\n",
            "(5907.223806694067, 5917.995699594718)\n",
            "Shape of predicted ratings: (1542, 111)\n",
            "Predicted ratings:\n",
            "[[4.44594755 3.92416007 4.00059579 ... 4.7267959  5.         3.45662805]\n",
            " [3.48772751 2.96594003 3.04237575 ... 3.76857587 4.33217361 2.49840802]\n",
            " [4.25690449 3.735117   3.81155273 ... 4.53775284 5.         3.26758499]\n",
            " ...\n",
            " [2.87798641 2.35619892 2.43263465 ... 3.15883476 3.72243251 1.88866691]\n",
            " [2.72644906 2.20466157 2.2810973  ... 3.00729741 3.57089516 1.73712956]\n",
            " [4.31368239 3.7918949  3.86833063 ... 4.59453074 5.         3.32436289]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example user and movie IDs\n",
        "user_id = 133\n",
        "movie_id = 76\n",
        "\n",
        "# Extract the predicted rating for the specified user and movie\n",
        "predicted_rating = predicted_ratings[user_id, movie_id]\n",
        "\n",
        "print(f\"Predicted rating for user {user_id} on movie {movie_id}: {predicted_rating}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwsyCPaMXydb",
        "outputId": "8491c326-4d95-4bcd-9fce-ee8f33748880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 133 on movie 76: 3.5897852190368917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the squared error\n",
        "squared_error = (predicted_rating - user_133_ratings) ** 2\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(squared_error)\n",
        "\n",
        "print(\"RMSE for the Baseline Estimate Model for a User ID 133:\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WaBIAb9mzwK",
        "outputId": "c4f9c29b-65fb-40c1-95f4-21986ee2c587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE for the Baseline Estimate Model for a User ID 133: 0.41021478096310826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxdBwP_m8SYK"
      },
      "source": [
        "**2. Correlation-Based Neighbourhood Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sB9LmmS1BFz",
        "outputId": "6c47891a-ff6e-4932-b61c-ce3c1b2bd7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 111)\n",
            "Computation...\n",
            "10114.624280999902\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt\n",
        "from time import time\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Non-vectorized way (iterate through each r_ui)\n",
        "#################################################\n",
        "def predict_r_ui(mat, u, i, mu, S, Sk_iu, baseline_bu, baseline_bi):\n",
        "  bui = mu + baseline_bu[u] + baseline_bi[0, i]\n",
        "  buj = mu + baseline_bu[u] + baseline_bi[0, Sk_iu]\n",
        "  return bui + 1 / S[i, Sk_iu].sum() * (S[i, Sk_iu].toarray().ravel() * (mat[u, Sk_iu].toarray().ravel() - buj)).sum()\n",
        "\n",
        "def correlation_based_neighbourhood_model(mat, mat_file, l_reg2=100.0, k=250):\n",
        "    # subsample the matrix to make computation faster\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "\n",
        "    #baseline_bu, baseline_bi = baseline_estimator(mat)\n",
        "    # We should call baseline_estimator but we can init at random for test\n",
        "    baseline_bu, baseline_bi = np.random.rand(no_users, 1)  * 2 - 1, np.random.rand(1, no_movies) * 2 - 1\n",
        "\n",
        "    #bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "\n",
        "    # Compute similarity matrix\n",
        "    N = sparse.csr_matrix(mat).copy()\n",
        "    N.data[:] = 1\n",
        "    S = sparse.csr_matrix.dot(N.T, N)\n",
        "    S.data[:] = S.data[:] / (S.data[:] + l_reg2)\n",
        "    S = S * compute_sparse_correlation_matrix(mat)\n",
        "\n",
        "    # Computation\n",
        "    print(\"Computation...\")\n",
        "    n_iter = 200\n",
        "    cx = mat.tocoo()\n",
        "    r_ui_mat = []\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        Sk_iu = np.flip(np.argsort(S[i,].toarray()))[:k].ravel()\n",
        "        r_ui = predict_r_ui(mat, u, i, mu, S, Sk_iu, baseline_bu, baseline_bi)\n",
        "        r_ui_mat.append((u, i, r_ui[0]))\n",
        "\n",
        "    data = list(map(lambda x: x[2], r_ui_mat))\n",
        "    col = list(map(lambda x: x[1], r_ui_mat))\n",
        "    row = list(map(lambda x: x[0], r_ui_mat))\n",
        "    r_ui_pred = sparse.csr_matrix((data, (row, col)), shape=mat.shape)\n",
        "\n",
        "    print((mat - r_ui_pred).sum())\n",
        "\n",
        "    return r_ui_pred\n",
        "\n",
        "#################################################\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mat_file = path+\"/T.mat\"\n",
        "    mat = io.loadmat(mat_file)['X']\n",
        "    correlation_based_neighbourhood_model(mat, mat_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZcQ8I_F8GR5"
      },
      "source": [
        "**3. Correlation-Based Neighbourhood Model with Implicit Feedback**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz3SZ_D31OK2",
        "outputId": "2e8dd9e2-b841-4045-86c9-3a65890cf296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 111)\n",
            "Pre-processing done.\n",
            "Train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-e237adf18e5c>:80: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  bi[0, i] += gamma * (e_ui - l_reg * bi[0, i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \\  200 (6.8 sec)\n",
            "compute loss...\n",
            "(array([5498.81172662]), array([9559.91821404]))\n",
            "10 \\  200 (4.7 sec)\n",
            "compute loss...\n",
            "(array([3317.24117512]), array([6841.28338918]))\n",
            "20 \\  200 (4.9 sec)\n",
            "compute loss...\n",
            "(array([2600.90291121]), array([5838.16702128]))\n",
            "30 \\  200 (4.1 sec)\n",
            "compute loss...\n",
            "(array([2177.03906077]), array([5235.90083425]))\n",
            "40 \\  200 (3.5 sec)\n",
            "compute loss...\n",
            "(array([1896.13059495]), array([4834.91826319]))\n",
            "50 \\  200 (3.5 sec)\n",
            "compute loss...\n",
            "(array([1696.87676655]), array([4550.67184563]))\n",
            "60 \\  200 (3.5 sec)\n",
            "compute loss...\n",
            "(array([1548.82399094]), array([4340.31799786]))\n",
            "70 \\  200 (4 sec)\n",
            "compute loss...\n",
            "(array([1435.04545887]), array([4179.67972152]))\n",
            "80 \\  200 (4.1 sec)\n",
            "compute loss...\n",
            "(array([1345.34088596]), array([4054.01808392]))\n",
            "90 \\  200 (5.1 sec)\n",
            "compute loss...\n",
            "(array([1273.17601826]), array([3953.81220341]))\n",
            "100 \\  200 (3.9 sec)\n",
            "compute loss...\n",
            "(array([1214.16278473]), array([3872.63301199]))\n",
            "110 \\  200 (3.4 sec)\n",
            "compute loss...\n",
            "(array([1165.2432559]), array([3805.98628368]))\n",
            "120 \\  200 (3.4 sec)\n",
            "compute loss...\n",
            "(array([1124.22258133]), array([3750.64248501]))\n",
            "130 \\  200 (3.4 sec)\n",
            "compute loss...\n",
            "(array([1089.48710594]), array([3704.22818513]))\n",
            "140 \\  200 (3.4 sec)\n",
            "compute loss...\n",
            "(array([1059.82650028]), array([3664.96612506]))\n",
            "150 \\  200 (3.4 sec)\n",
            "compute loss...\n",
            "(array([1034.31720283]), array([3631.5038659]))\n",
            "160 \\  200 (3.4 sec)\n",
            "compute loss...\n",
            "(array([1012.24355541]), array([3602.79739898]))\n",
            "170 \\  200 (3.9 sec)\n",
            "compute loss...\n",
            "(array([993.04301796]), array([3578.03010898]))\n",
            "180 \\  200 (4.9 sec)\n",
            "compute loss...\n",
            "(array([976.26733039]), array([3556.55523535]))\n",
            "190 \\  200 (4.4 sec)\n",
            "compute loss...\n",
            "(array([961.55458518]), array([3537.85441538]))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt\n",
        "from time import time\n",
        "\n",
        "\n",
        "\n",
        "# Through all this code Rk_iu and Nk_iu are the same since implicit matrix is\n",
        "#    made from the rating matrix without additional information (i.e. indexes of\n",
        "#    non-zero elements are the same therefore neighbors too).\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Non-vectorized way (iterate through each r_ui)\n",
        "#################################################\n",
        "def predict_r_ui_newmodel(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi):\n",
        "    buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "    Rk_iu_sum = np.multiply((mat[u, Rk_iu] - buj), wij[i][Rk_iu]).sum()\n",
        "    Nk_iu_sum = cij[i][Rk_iu].sum()\n",
        "    return mu + bu[u] + bi[0, i] + Rk_iu_sum / sqrt(len(Rk_iu)) + Nk_iu_sum / sqrt(len(Nk_iu))\n",
        "\n",
        "def compute_e_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi):\n",
        "    return mat[u, i] - predict_r_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi)\n",
        "\n",
        "def compute_loss(mat, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, l_reg=0.002):\n",
        "    loss = 0\n",
        "    loss_reg = 0\n",
        "    cx = mat.tocoo()\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        r_ui_pred = predict_r_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi)\n",
        "        Rk_iu_sum = (wij[i][Rk_iu] ** 2).sum()\n",
        "        Nk_iu_sum = (cij[i][Rk_iu] ** 2).sum()\n",
        "        loss += (mat[u, i] - r_ui_pred) ** 2\n",
        "        loss_reg += l_reg * ((bu ** 2).sum() + (bi ** 2).sum() + Rk_iu_sum + Nk_iu_sum)\n",
        "\n",
        "    return loss, loss+loss_reg\n",
        "\n",
        "def correlation_based_implicit_neighbourhood_model(mat, mat_file, l_reg=0.002, gamma=0.005, l_reg2=100.0, k=250):\n",
        "    # subsample the matrix to make computation faster\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "\n",
        "    #baseline_bu, baseline_bi = baseline_estimator(mat)\n",
        "    # We should call baseline_estimator but we can init at random for test\n",
        "    baseline_bu, baseline_bi = np.random.rand(no_users, 1)  * 2 - 1, np.random.rand(1, no_movies) * 2 - 1\n",
        "\n",
        "    bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "    # Init parameters\n",
        "    bu = np.random.rand(no_users, 1)  * 2 - 1\n",
        "    bi = np.random.rand(1, no_movies) * 2 - 1\n",
        "    wij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "    cij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "\n",
        "    # Compute similarity matrix\n",
        "    N = sparse.csr_matrix(mat).copy()\n",
        "    N.data[:] = 1\n",
        "    S = sparse.csr_matrix.dot(N.T, N)\n",
        "    S.data[:] = S.data[:] / (S.data[:] + l_reg2)\n",
        "    S = S * compute_sparse_correlation_matrix(mat)\n",
        "\n",
        "    # Train\n",
        "    print(\"Train...\")\n",
        "    n_iter = 200\n",
        "    cx = mat.tocoo()\n",
        "    for it in range(n_iter):\n",
        "        t0 = time()\n",
        "        for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "            #Rk_iu = Nk_iu = bi_index[u]\n",
        "            Rk_iu = Nk_iu = np.flip(np.argsort(S[i,].toarray()))[:k].ravel()\n",
        "            e_ui = compute_e_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi)\n",
        "\n",
        "            bu[u] += gamma * (e_ui - l_reg * bu[u])\n",
        "            bi[0, i] += gamma * (e_ui - l_reg * bi[0, i])\n",
        "\n",
        "            buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "            wij[i][Rk_iu] += gamma * ( 1 / sqrt(len(Rk_iu)) * e_ui * (mat[u, Rk_iu].toarray().ravel() - buj) - l_reg * wij[i][Rk_iu] )\n",
        "            cij[i][Nk_iu] += gamma * ( 1 / sqrt(len(Nk_iu)) * e_ui - l_reg * cij[i][Nk_iu] )\n",
        "        gamma *= 0.99\n",
        "\n",
        "        if it % 10 == 0:\n",
        "          t1 = time()\n",
        "          print(it, \"\\ \", n_iter, \"(%.2g sec)\" % (t1 - t0))\n",
        "          print(\"compute loss...\")\n",
        "          print(compute_loss(mat, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, l_reg=l_reg))\n",
        "\n",
        "    return bu, bi, wij, cij\n",
        "#################################################\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Vectorized way (in work)\n",
        "# (Actually this version is faster but updates e_ui\n",
        "# less frequently making it less accurate for the\n",
        "# gradient descent)\n",
        "#################################################\n",
        "def compute_e_vectorized(mat, mu, bu, bi, Rk, wij, Nk, cij, baseline_bu, baseline_bi):\n",
        "    # Rk and Nk are list of tuple (u, i, Rk_iu/Nk_iu)\n",
        "\n",
        "    no_users_entries = np.array((mat != 0).sum(1)).T.ravel()\n",
        "    bu_rep = np.repeat(bu.ravel(), no_users_entries)\n",
        "\n",
        "    no_movies_entries = np.array((mat != 0).sum(0)).ravel()\n",
        "    bi_rep = np.repeat(bi.ravel(), no_movies_entries)\n",
        "\n",
        "    temp_mat = sparse.csc_matrix(mat).copy()\n",
        "    temp_mat.data[:] -= mu\n",
        "    temp_mat.data[:] -= bi_rep\n",
        "    Rk_sum = np.array(list(map(lambda x : ( (mat[x[0], x[2]].toarray().ravel() \\\n",
        "                                           - (mu + baseline_bu[x[0]] + baseline_bi[0, x[2]])) \\\n",
        "                                           * wij[x[1]][x[2]] ).sum() / sqrt(len(x[2])), Rk)))\n",
        "    temp_mat.data[:] -= Rk_sum\n",
        "    Nk_sum = np.array(list(map(lambda x : cij[x[1]][x[2]].sum() / sqrt(len(x[2])), Nk)))\n",
        "    temp_mat.data[:] -= Nk_sum\n",
        "    temp_mat = sparse.coo_matrix(temp_mat)\n",
        "    temp_mat = sparse.csr_matrix(temp_mat)\n",
        "    temp_mat.data[:] -= bu_rep\n",
        "\n",
        "    return temp_mat\n",
        "\n",
        "def compute_loss_vectorized(mat, mu, bu, bi, Rk, wij, Nk, cij, baseline_bu, baseline_bi, l_reg=0.002):\n",
        "    no_nonzero_element = np.array((mat != 0).sum())\n",
        "    loss = (compute_e_vectorized(mat, mu, bu, bi, Rk, wij, Nk, cij, baseline_bu, baseline_bi).data[:] ** 2).sum()\n",
        "    loss_reg = l_reg * np.array(list(map(lambda x : (cij[x[1]][x[2]] ** 2).sum(), Nk))).sum()\n",
        "    loss_reg += l_reg * np.array(list(map(lambda x : (wij[x[1]][x[2]] ** 2).sum(), Rk))).sum()\n",
        "    loss_reg += no_nonzero_element * l_reg * (bu ** 2).sum()\n",
        "    loss_reg += no_nonzero_element * l_reg * (bi ** 2).sum()\n",
        "\n",
        "    return loss, loss+loss_reg\n",
        "\n",
        "def correlation_based_implicit_neighbourhood_model_vectorized(mat, mat_file, l_reg=0.002, gamma=0.005, l_reg2=100.0, k=250):\n",
        "    gamma /= 100\n",
        "\n",
        "    # subsample the matrix to make computation faster\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "    no_users_entries = np.array((mat != 0).sum(1))\n",
        "    no_movies_entries = np.array((mat != 0).sum(0))\n",
        "\n",
        "    #baseline_bu, baseline_bi = baseline_estimator(mat)\n",
        "    # We should call baseline_estimator but we can init at random for testing\n",
        "    baseline_bu, baseline_bi = np.random.rand(no_users, 1)  * 2 - 1, np.random.rand(1, no_movies) * 2 - 1\n",
        "\n",
        "    bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "    bu = np.random.rand(no_users, 1)  * 2 - 1\n",
        "    bi = np.random.rand(1, no_movies) * 2 - 1\n",
        "    wij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "    cij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "\n",
        "    # Compute similarity matrix\n",
        "    N = sparse.csr_matrix(mat).copy()\n",
        "    N.data[:] = 1\n",
        "    S = sparse.csr_matrix.dot(N.T, N)\n",
        "    S.data[:] = S.data[:] / (S.data[:] + l_reg2)\n",
        "    S = S * compute_sparse_correlation_matrix(mat)\n",
        "\n",
        "    Rk = []\n",
        "    cx = mat.tocoo()\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        Rk.append((u, i, np.flip(np.argsort(S[i,].toarray()))[:k].ravel()))\n",
        "\n",
        "    # Train\n",
        "    print(\"Train...\")\n",
        "    n_iter = 200\n",
        "    for it in range(n_iter):\n",
        "        t0 = time()\n",
        "\n",
        "        e = compute_e_vectorized(mat, mu, bu, bi, Rk, wij, Rk, cij, baseline_bu, baseline_bi)\n",
        "        # Vectorized operations\n",
        "        bu += gamma * (e.sum(1) - no_users_entries * l_reg * bu)\n",
        "        bi += gamma * (e.sum(0) - no_movies_entries * l_reg * bi)\n",
        "\n",
        "        # TODO: vectorize the following\n",
        "        for u, i, Rk_iu in Rk:\n",
        "            Nk_iu = Rk_iu\n",
        "            e_ui = e[u, i]\n",
        "            buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "            wij[i][Rk_iu] += gamma * ( 1 / sqrt(len(Rk_iu)) * e_ui * (mat[u, Rk_iu].toarray().ravel() - buj) - l_reg * wij[i][Rk_iu] )\n",
        "            cij[i][Nk_iu] += gamma * ( 1 / sqrt(len(Nk_iu)) * e_ui - l_reg * cij[i][Nk_iu] )\n",
        "        gamma *= 0.99\n",
        "\n",
        "        if it % 10 == 0:\n",
        "          t1 = time()\n",
        "          print(it, \"\\ \", n_iter, \"(%.2g sec)\" % (t1 - t0))\n",
        "          print(\"compute loss...\")\n",
        "          print(compute_loss_vectorized(mat, mu, bu, bi, Rk, wij, Rk, cij, baseline_bu, baseline_bi, l_reg=l_reg))\n",
        "\n",
        "    return bu, bi, wij, cij\n",
        "#################################################\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mat_file = path+\"/T.mat\"\n",
        "    mat = io.loadmat(mat_file)['X']\n",
        "    correlation_based_implicit_neighbourhood_model(mat, mat_file)\n",
        "    #correlation_based_implicit_neighbourhood_model_vectorized(mat, mat_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**correlation_based_neighbourhood_model_weighted**"
      ],
      "metadata": {
        "id": "EUYSRgbIvW92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt\n",
        "from time import time\n",
        "\n",
        "def predict_r_ui_wgtngbr(mat, u, i, mu, bu, bi, Sk_iu, theta_ui, baseline_bu, baseline_bi):\n",
        "    buj = mu + baseline_bu[u] + baseline_bi[0, Sk_iu]\n",
        "    return bu[u] + bi[0, i] + np.sum(theta_ui * (mat[u, Sk_iu].toarray().ravel() - buj))\n",
        "\n",
        "def compute_e_ui(mat, u, i, mu, bu, bi, Sk_iu, theta_ui, baseline_bu, baseline_bi):\n",
        "    return mat[u, i] - predict_r_ui(mat, u, i, mu, bu, bi, Sk_iu, theta_ui, baseline_bu, baseline_bi)\n",
        "\n",
        "def compute_loss(mat, mu, bu, bi, Sk_iu, theta_ui, baseline_bu, baseline_bi, l_reg=0.002):\n",
        "    loss = 0\n",
        "    loss_reg = 0\n",
        "    cx = mat.tocoo()\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        r_ui_pred = predict_r_ui(mat, u, i, mu, bu, bi, Sk_iu, theta_ui, baseline_bu, baseline_bi)\n",
        "        loss += (mat[u, i] - r_ui_pred) ** 2\n",
        "\n",
        "    # Regularization term\n",
        "    loss_reg += l_reg * ((bu ** 2).sum() + (bi ** 2).sum() + (theta_ui ** 2).sum())\n",
        "\n",
        "    return loss, loss + loss_reg\n",
        "\n",
        "def correlation_based_neighbourhood_model_weighted(mat, mat_file, l_reg=0.002, gamma=0.005, k=250):\n",
        "    # subsample the matrix to make computation faster\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "\n",
        "    # Initialize parameters randomly\n",
        "    baseline_bu, baseline_bi = np.random.rand(no_users, 1)  * 2 - 1, np.random.rand(1, no_movies) * 2 - 1\n",
        "    bu = np.random.rand(no_users, 1)  * 2 - 1\n",
        "    bi = np.random.rand(1, no_movies) * 2 - 1\n",
        "    theta_ui = np.random.rand(no_movies, k) * 2 - 1\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "\n",
        "    # Train\n",
        "    print(\"Training...\")\n",
        "    n_iter = 200\n",
        "    cx = mat.tocoo()\n",
        "    for it in range(n_iter):\n",
        "        t0 = time()\n",
        "        for u, i, v in zip(cx.row, cx.col, cx.data):\n",
        "            Sk_iu = np.flip(np.argsort(S[i, ].toarray()))[:k].ravel()\n",
        "            e_ui = compute_e_ui(mat, u, i, mu, bu, bi, Sk_iu, theta_ui[i], baseline_bu, baseline_bi)\n",
        "\n",
        "            bu[u] += gamma * (e_ui - l_reg * bu[u])\n",
        "            bi[0, i] += gamma * (e_ui - l_reg * bi[0, i])\n",
        "\n",
        "            buj = mu + baseline_bu[u] + baseline_bi[0, Sk_iu]\n",
        "            theta_ui[i] += gamma * (e_ui * (mat[u, Sk_iu].toarray().ravel() - buj) - l_reg * theta_ui[i])\n",
        "\n",
        "        gamma *= 0.99\n",
        "\n",
        "        if it % 10 == 0:\n",
        "            t1 = time()\n",
        "            print(\"Iteration:\", it, \"/\", n_iter, \"(%.2g sec)\" % (t1 - t0))\n",
        "            print(\"Compute loss...\")\n",
        "            print(compute_loss(mat, mu, bu, bi, Sk_iu, theta_ui[i], baseline_bu, baseline_bi, l_reg=l_reg))\n",
        "\n",
        "    return bu, bi, theta_ui\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mat_file = path + \"/T.mat\"\n",
        "    mat = io.loadmat(mat_file)['X']\n",
        "    correlation_based_neighbourhood_model_weighted(mat, mat_file)\n"
      ],
      "metadata": {
        "id": "TPB6oomnvLzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nEub0WN54sy"
      },
      "source": [
        "**4. SVD++**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JBi-Iyk42nk",
        "outputId": "f9ffdc3f-dc4e-43fb-e46d-8769dc1fe7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 111)\n",
            "Pre-processing done.\n",
            "Train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5d9ebb8e95c6>:59: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  bi[0, i] += gamma1 * (e_ui - l_reg6 * bi[0, i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \\  200\n",
            "compute loss...\n",
            "(array([13791.37048199]), array([24791.32424838]))\n",
            "10 \\  200\n",
            "compute loss...\n",
            "(array([6959.23481364]), array([16958.51812551]))\n",
            "20 \\  200\n",
            "compute loss...\n",
            "(array([6401.33030715]), array([16191.55471676]))\n",
            "30 \\  200\n",
            "compute loss...\n",
            "(array([6241.52771747]), array([15966.57500216]))\n",
            "40 \\  200\n",
            "compute loss...\n",
            "(array([6189.01541564]), array([15892.16051591]))\n",
            "50 \\  200\n",
            "compute loss...\n",
            "(array([6171.06434054]), array([15866.66880155]))\n",
            "60 \\  200\n",
            "compute loss...\n",
            "(array([6164.84760227]), array([15857.83434017]))\n",
            "70 \\  200\n",
            "compute loss...\n",
            "(array([6162.68506636]), array([15854.7604565]))\n",
            "80 \\  200\n",
            "compute loss...\n",
            "(array([6161.93165548]), array([15853.68944773]))\n",
            "90 \\  200\n",
            "compute loss...\n",
            "(array([6161.66903248]), array([15853.31610578]))\n",
            "100 \\  200\n",
            "compute loss...\n",
            "(array([6161.57747064]), array([15853.18594113]))\n",
            "110 \\  200\n",
            "compute loss...\n",
            "(array([6161.54554611]), array([15853.14055693]))\n",
            "120 \\  200\n",
            "compute loss...\n",
            "(array([6161.53441485]), array([15853.12473261]))\n",
            "130 \\  200\n",
            "compute loss...\n",
            "(array([6161.53053363]), array([15853.11921504]))\n",
            "140 \\  200\n",
            "compute loss...\n",
            "(array([6161.52918034]), array([15853.11729118]))\n",
            "150 \\  200\n",
            "compute loss...\n",
            "(array([6161.52870847]), array([15853.11662037]))\n",
            "160 \\  200\n",
            "compute loss...\n",
            "(array([6161.52854394]), array([15853.11638648]))\n",
            "170 \\  200\n",
            "compute loss...\n",
            "(array([6161.52848658]), array([15853.11630492]))\n",
            "180 \\  200\n",
            "compute loss...\n",
            "(array([6161.52846657]), array([15853.11627648]))\n",
            "190 \\  200\n",
            "compute loss...\n",
            "(array([6161.5284596]), array([15853.11626657]))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt, isnan\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Non-vectorized way\n",
        "#################################################\n",
        "def predict_r_ui_svd_more_more(mat, u, i, mu, bu, bi, qi, pu, N_u, yj):\n",
        "    N_u_sum = yj[N_u].sum(0)\n",
        "    return mu + bu[u] + bi[0, i] + np.dot(qi[i], (pu[u] + N_u_sum / sqrt(len(N_u))))\n",
        "\n",
        "def compute_e_ui(mat, u, i, mu, bu, bi, qi, pu, N_u, yj):\n",
        "    return mat[u, i] - predict_r_ui(mat, u, i, mu, bu, bi, qi, pu, N_u, yj)\n",
        "\n",
        "def compute_loss(mat, mu, bu, bi, qi, pu, N_u, yj, l_reg6=0.005, l_reg7=0.015):\n",
        "    loss = 0\n",
        "    loss_reg = 0\n",
        "    cx = mat.tocoo()\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        r_ui_pred = predict_r_ui(mat, u, i, mu, bu, bi, qi, pu, N_u, yj)\n",
        "        loss += (mat[u, i] - r_ui_pred) ** 2\n",
        "        loss_reg += l_reg6 * ((bu ** 2).sum() + (bi ** 2).sum())\n",
        "        loss_reg += l_reg7 * ((qi[i]**2).sum() + (pu[u]**2).sum() + (yj[N_u]**2).sum())\n",
        "\n",
        "    return loss, loss+loss_reg\n",
        "\n",
        "def svd_more_more(mat, mat_file, gamma1=0.007, gamma2=0.007, gamma3=0.001, l_reg2=100, l_reg6=0.005, l_reg7=0.015, f=50):\n",
        "    # subsample the matrix to make computation faster\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "\n",
        "    bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "    # Init parameters\n",
        "    bu = np.random.rand(no_users, 1)  * 2 - 1\n",
        "    bi = np.random.rand(1, no_movies) * 2 - 1\n",
        "    qi = np.random.rand(no_movies, f) * 2 - 1\n",
        "    pu = np.random.rand(no_users, f) * 2 - 1\n",
        "    yj = np.random.rand(no_movies, f) * 2 - 1\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "\n",
        "    # Train\n",
        "    print(\"Train...\")\n",
        "    n_iter = 200\n",
        "    cx = mat.tocoo()\n",
        "    for it in range(n_iter):\n",
        "        for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "            N_u = bi_index[u]\n",
        "            e_ui = compute_e_ui(mat, u, i, mu, bu, bi, qi, pu, N_u, yj)\n",
        "\n",
        "            bu[u] += gamma1 * (e_ui - l_reg6 * bu[u])\n",
        "            bi[0, i] += gamma1 * (e_ui - l_reg6 * bi[0, i])\n",
        "            qi[i] += gamma2 * (e_ui * (pu[u] + 1 / sqrt(len(N_u)) * yj[N_u].sum(0)) - l_reg7 * qi[i])\n",
        "            pu[u] += gamma2 * (e_ui * qi[i] - l_reg7 * pu[u])\n",
        "            yj[N_u] += gamma2 * (e_ui * 1/ sqrt(len(N_u)) * qi[i] - l_reg7 * yj[N_u])\n",
        "        gamma1 *= 0.9\n",
        "        gamma2 *= 0.9\n",
        "\n",
        "        if it % 10 == 0:\n",
        "          print(it, \"\\ \", n_iter)\n",
        "          print(\"compute loss...\")\n",
        "          print(compute_loss(mat, mu, bu, bi, qi, pu, N_u, yj, l_reg6=l_reg6, l_reg7=l_reg7))\n",
        "\n",
        "    return bu, bi, qi, pu, yj\n",
        "#################################################\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mat_file = path+\"/T.mat\"\n",
        "    mat = io.loadmat(mat_file)['X']\n",
        "    svd_more_more(mat, mat_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0skqp-dQ5vS-"
      },
      "source": [
        "**5. Integrated Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9cq2CpF5bYi",
        "outputId": "0a9fe2d2-4992-47da-ad9e-3dc28dd9f4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 111)\n",
            "Pre-processing done.\n",
            "Train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-cab9bb462c9a>:82: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  bi[0, i] += gamma1 * (e_ui - l_reg6 * bi[0, i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \\  200\n",
            "compute loss...\n",
            "(array([18479.92145893]), array([33088.92550973]))\n",
            "10 \\  200\n",
            "compute loss...\n",
            "(array([8525.58317152]), array([21951.68063541]))\n",
            "20 \\  200\n",
            "compute loss...\n",
            "(array([7870.74889857]), array([21029.50474812]))\n",
            "30 \\  200\n",
            "compute loss...\n",
            "(array([7684.53851369]), array([20758.27904793]))\n",
            "40 \\  200\n",
            "compute loss...\n",
            "(array([7623.36835439]), array([20668.3486542]))\n",
            "50 \\  200\n",
            "compute loss...\n",
            "(array([7602.45400852]), array([20637.50956313]))\n",
            "60 \\  200\n",
            "compute loss...\n",
            "(array([7595.21031083]), array([20626.81772249]))\n",
            "70 \\  200\n",
            "compute loss...\n",
            "(array([7592.6904378]), array([20623.09705742]))\n",
            "80 \\  200\n",
            "compute loss...\n",
            "(array([7591.81252043]), array([20621.80063197]))\n",
            "90 \\  200\n",
            "compute loss...\n",
            "(array([7591.50649552]), array([20621.34870446]))\n",
            "100 \\  200\n",
            "compute loss...\n",
            "(array([7591.39980168]), array([20621.19114022]))\n",
            "110 \\  200\n",
            "compute loss...\n",
            "(array([7591.3626011]), array([20621.13620256]))\n",
            "120 \\  200\n",
            "compute loss...\n",
            "(array([7591.34963022]), array([20621.11704717]))\n",
            "130 \\  200\n",
            "compute loss...\n",
            "(array([7591.34510757]), array([20621.11036813]))\n",
            "140 \\  200\n",
            "compute loss...\n",
            "(array([7591.34353062]), array([20621.10803929]))\n",
            "150 \\  200\n",
            "compute loss...\n",
            "(array([7591.34298078]), array([20621.10722728]))\n",
            "160 \\  200\n",
            "compute loss...\n",
            "(array([7591.34278906]), array([20621.10694415]))\n",
            "170 \\  200\n",
            "compute loss...\n",
            "(array([7591.34272221]), array([20621.10684542]))\n",
            "180 \\  200\n",
            "compute loss...\n",
            "(array([7591.3426989]), array([20621.106811]))\n",
            "190 \\  200\n",
            "compute loss...\n",
            "(array([7591.34269077]), array([20621.106799]))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt, isnan\n",
        "\n",
        "\n",
        "\n",
        "# Through all this code Rk_iu and Nk_iu are the same since implicit matrix is\n",
        "#    made from the rating matrix without additional information.\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Non-vectorized way\n",
        "#################################################\n",
        "def predict_r_ui_integrated(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj):\n",
        "    buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "    Rk_iu_sum = np.multiply((mat[u, Rk_iu] - buj), wij[i][Rk_iu]).sum()\n",
        "    Nk_iu_sum = cij[i][Rk_iu].sum()\n",
        "    N_u_sum = yj[N_u].sum(0)\n",
        "    return mu + bu[u] + bi[0, i] + np.dot(qi[i], (pu[u] + N_u_sum / sqrt(len(N_u)))) + Rk_iu_sum / sqrt(len(Rk_iu)) + Nk_iu_sum / sqrt(len(Nk_iu))\n",
        "\n",
        "def compute_e_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj):\n",
        "    return mat[u, i] - predict_r_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "\n",
        "def compute_loss(mat, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj, l_reg6=0.005, l_reg7=0.015, l_reg8=0.015):\n",
        "    loss = 0\n",
        "    loss_reg = 0\n",
        "    cx = mat.tocoo()\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        r_ui_pred = predict_r_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "        Rk_iu_sum = (wij[i][Rk_iu] ** 2).sum()\n",
        "        Nk_iu_sum = (cij[i][Rk_iu] ** 2).sum()\n",
        "        loss += (mat[u, i] - r_ui_pred) ** 2\n",
        "        loss_reg += l_reg6 * ((bu ** 2).sum() + (bi ** 2).sum())\n",
        "        loss_reg += l_reg8 * (Rk_iu_sum + Nk_iu_sum)\n",
        "        loss_reg += l_reg7 * ((qi[i]**2).sum() + (pu[u]**2).sum() + (yj[N_u]**2).sum())\n",
        "\n",
        "    return loss, loss+loss_reg\n",
        "\n",
        "def integrated_model(mat, mat_file, gamma1=0.007, gamma2=0.007, gamma3=0.001, l_reg2=100, l_reg6=0.005, l_reg7=0.015, l_reg8=0.015, k=300, f=50):\n",
        "    # subsample the matrix to make computation faster\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "\n",
        "    #baseline_bu, baseline_bi = baseline_estimator(mat)\n",
        "    # We should call baseline_estimator but we can init at random for test\n",
        "    baseline_bu, baseline_bi = np.random.rand(no_users, 1)  * 2 - 1, np.random.rand(1, no_movies) * 2 - 1\n",
        "\n",
        "    bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "    # Init parameters\n",
        "    bu = np.random.rand(no_users, 1)  * 2 - 1\n",
        "    bi = np.random.rand(1, no_movies) * 2 - 1\n",
        "    wij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "    cij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "    qi = np.random.rand(no_movies, f) * 2 - 1\n",
        "    pu = np.random.rand(no_users, f) * 2 - 1\n",
        "    yj = np.random.rand(no_movies, f) * 2 - 1\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "    N = sparse.csr_matrix(mat).copy()\n",
        "    N.data[:] = 1\n",
        "    S = sparse.csr_matrix.dot(N.T, N)\n",
        "    S.data[:] = S.data[:] / (S.data[:] + l_reg2)\n",
        "    S = S * compute_sparse_correlation_matrix(mat)\n",
        "\n",
        "    # Train\n",
        "    print(\"Train...\")\n",
        "    n_iter = 200\n",
        "    cx = mat.tocoo()\n",
        "    for it in range(n_iter):\n",
        "        for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "            #Rk_iu = Nk_iu = bi_index[u]\n",
        "            N_u = bi_index[u]\n",
        "            Rk_iu = Nk_iu = np.flip(np.argsort(S[i,].toarray()))[:k].ravel()\n",
        "            e_ui = compute_e_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "\n",
        "            bu[u] += gamma1 * (e_ui - l_reg6 * bu[u])\n",
        "            bi[0, i] += gamma1 * (e_ui - l_reg6 * bi[0, i])\n",
        "            qi[i] += gamma2 * (e_ui * (pu[u] + 1 / sqrt(len(N_u)) * yj[N_u].sum(0)) - l_reg7 * qi[i])\n",
        "            pu[u] += gamma2 * (e_ui * qi[i] - l_reg7 * pu[u])\n",
        "            yj[N_u] += gamma2 * (e_ui * 1/ sqrt(len(N_u)) * qi[i] - l_reg7 * yj[N_u])\n",
        "            buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "            wij[i][Rk_iu] += gamma3 * ( 1 / sqrt(len(Rk_iu)) * e_ui * (mat[u, Rk_iu].toarray().ravel() - buj) - l_reg8 * wij[i][Rk_iu] )\n",
        "            cij[i][Nk_iu] += gamma3 * ( 1 / sqrt(len(Nk_iu)) * e_ui - l_reg8 * cij[i][Nk_iu] )\n",
        "        gamma1 *= 0.9\n",
        "        gamma2 *= 0.9\n",
        "        gamma3 *= 0.9\n",
        "\n",
        "        if it % 10 == 0:\n",
        "          print(it, \"\\ \", n_iter)\n",
        "          print(\"compute loss...\")\n",
        "          print(compute_loss(mat, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj, l_reg6=l_reg6, l_reg7=l_reg7, l_reg8=l_reg8))\n",
        "\n",
        "    return bu, bi, qi, pu, yj, wij, cij\n",
        "#################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mat_file = path+\"/T.mat\"\n",
        "    mat = io.loadmat(mat_file)['X']\n",
        "    integrated_model(mat, mat_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt, isnan\n",
        "\n",
        "\n",
        "\n",
        "# Through all this code Rk_iu and Nk_iu are the same since implicit matrix is\n",
        "#    made from the rating matrix without additional information.\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Non-vectorized way\n",
        "#################################################\n",
        "def predict_r_ui_integrated(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj):\n",
        "    buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "    Rk_iu_sum = np.multiply((mat[u, Rk_iu] - buj), wij[i][Rk_iu]).sum()\n",
        "    Nk_iu_sum = cij[i][Rk_iu].sum()\n",
        "    N_u_sum = yj[N_u].sum(0)\n",
        "    return mu + bu[u] + bi[0, i] + np.dot(qi[i], (pu[u] + N_u_sum / sqrt(len(N_u)))) + Rk_iu_sum / sqrt(len(Rk_iu)) + Nk_iu_sum / sqrt(len(Nk_iu))\n",
        "\n",
        "def compute_e_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj):\n",
        "    return mat[u, i] - predict_r_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "\n",
        "def compute_loss(mat, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj, l_reg6=0.005, l_reg7=0.015, l_reg8=0.015):\n",
        "    loss = 0\n",
        "    loss_reg = 0\n",
        "    cx = mat.tocoo()\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        r_ui_pred = predict_r_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "        Rk_iu_sum = (wij[i][Rk_iu] ** 2).sum()\n",
        "        Nk_iu_sum = (cij[i][Rk_iu] ** 2).sum()\n",
        "        loss += (mat[u, i] - r_ui_pred) ** 2\n",
        "        loss_reg += l_reg6 * ((bu ** 2).sum() + (bi ** 2).sum())\n",
        "        loss_reg += l_reg8 * (Rk_iu_sum + Nk_iu_sum)\n",
        "        loss_reg += l_reg7 * ((qi[i]**2).sum() + (pu[u]**2).sum() + (yj[N_u]**2).sum())\n",
        "\n",
        "    return loss, loss+loss_reg\n",
        "\n",
        "def integrated_model(mat, mat_file, gamma1=0.007, gamma2=0.007, gamma3=0.001, l_reg2=100, l_reg6=0.005, l_reg7=0.015, l_reg8=0.015, k=300, f=50):\n",
        "    # subsample the matrix to make computation faster\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "\n",
        "    #baseline_bu, baseline_bi = baseline_estimator(mat)\n",
        "    # We should call baseline_estimator but we can init at random for test\n",
        "    baseline_bu, baseline_bi = np.random.rand(no_users, 1)  * 2 - 1, np.random.rand(1, no_movies) * 2 - 1\n",
        "\n",
        "    bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "    # Init parameters\n",
        "    bu = np.random.rand(no_users, 1)  * 2 - 1\n",
        "    bi = np.random.rand(1, no_movies) * 2 - 1\n",
        "    wij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "    cij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "    qi = np.random.rand(no_movies, f) * 2 - 1\n",
        "    pu = np.random.rand(no_users, f) * 2 - 1\n",
        "    yj = np.random.rand(no_movies, f) * 2 - 1\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "    N = sparse.csr_matrix(mat).copy()\n",
        "    N.data[:] = 1\n",
        "    S = sparse.csr_matrix.dot(N.T, N)\n",
        "    S.data[:] = S.data[:] / (S.data[:] + l_reg2)\n",
        "    S = S * compute_sparse_correlation_matrix(mat)\n",
        "\n",
        "    # Train\n",
        "    print(\"Train...\")\n",
        "    n_iter = 200\n",
        "    cx = mat.tocoo()\n",
        "    for it in range(n_iter):\n",
        "        for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "            #Rk_iu = Nk_iu = bi_index[u]\n",
        "            N_u = bi_index[u]\n",
        "            Rk_iu = Nk_iu = np.flip(np.argsort(S[i,].toarray()))[:k].ravel()\n",
        "            e_ui = compute_e_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "\n",
        "            bu[u] += gamma1 * (e_ui - l_reg6 * bu[u])\n",
        "            bi[0, i] += gamma1 * (e_ui - l_reg6 * bi[0, i])\n",
        "            qi[i] += gamma2 * (e_ui * (pu[u] + 1 / sqrt(len(N_u)) * yj[N_u].sum(0)) - l_reg7 * qi[i])\n",
        "            pu[u] += gamma2 * (e_ui * qi[i] - l_reg7 * pu[u])\n",
        "            yj[N_u] += gamma2 * (e_ui * 1/ sqrt(len(N_u)) * qi[i] - l_reg7 * yj[N_u])\n",
        "            buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "            wij[i][Rk_iu] += gamma3 * ( 1 / sqrt(len(Rk_iu)) * e_ui * (mat[u, Rk_iu].toarray().ravel() - buj) - l_reg8 * wij[i][Rk_iu] )\n",
        "            cij[i][Nk_iu] += gamma3 * ( 1 / sqrt(len(Nk_iu)) * e_ui - l_reg8 * cij[i][Nk_iu] )\n",
        "        gamma1 *= 0.9\n",
        "        gamma2 *= 0.9\n",
        "        gamma3 *= 0.9\n",
        "\n",
        "        if it % 10 == 0:\n",
        "          print(it, \"\\ \", n_iter)\n",
        "          print(\"compute loss...\")\n",
        "          print(compute_loss(mat, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj, l_reg6=l_reg6, l_reg7=l_reg7, l_reg8=l_reg8))\n",
        "\n",
        "    return bu, bi, qi, pu, yj, wij, cij, mu, Rk_iu, Nk_iu, baseline_bu, baseline_bi, N_u\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mat_file = path+\"/T.mat\"\n",
        "    mat = io.loadmat(mat_file)['X']\n",
        "    bu, bi, qi, pu, yj, wij, cij, mu, Rk_iu, Nk_iu, baseline_bu, baseline_bi, N_u = integrated_model(mat, mat_file)\n",
        "\n",
        "    # Example user and movie IDs\n",
        "    user_id = 133\n",
        "    movie_id = 76\n",
        "\n",
        "    # Calculate the rating prediction for the given user and movie\n",
        "    rating_prediction = predict_r_ui_integrated(mat, user_id, movie_id, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "    print(\"Predicted rating for user\", user_id, \"and movie\", movie_id, \":\", rating_prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOYJGrN3fcDR",
        "outputId": "12799e4d-cc38-4cfc-c64d-2671691013a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 111)\n",
            "Pre-processing done.\n",
            "Train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-15e84c8be0cc>:82: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  bi[0, i] += gamma1 * (e_ui - l_reg6 * bi[0, i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \\  200\n",
            "compute loss...\n",
            "(array([21654.61084155]), array([36679.73762154]))\n",
            "10 \\  200\n",
            "compute loss...\n",
            "(array([10556.25880131]), array([24317.68379767]))\n",
            "20 \\  200\n",
            "compute loss...\n",
            "(array([9602.46670484]), array([23076.1997271]))\n",
            "30 \\  200\n",
            "compute loss...\n",
            "(array([9329.16001158]), array([22711.25684652]))\n",
            "40 \\  200\n",
            "compute loss...\n",
            "(array([9238.73257574]), array([22589.81902253]))\n",
            "50 \\  200\n",
            "compute loss...\n",
            "(array([9207.74975886]), array([22548.13400577]))\n",
            "60 \\  200\n",
            "compute loss...\n",
            "(array([9197.01219801]), array([22533.67808617]))\n",
            "70 \\  200\n",
            "compute loss...\n",
            "(array([9193.27616483]), array([22528.64714776]))\n",
            "80 \\  200\n",
            "compute loss...\n",
            "(array([9191.97445229]), array([22526.89412469]))\n",
            "90 \\  200\n",
            "compute loss...\n",
            "(array([9191.52069005]), array([22526.28302389]))\n",
            "100 \\  200\n",
            "compute loss...\n",
            "(array([9191.36248714]), array([22526.0699633]))\n",
            "110 \\  200\n",
            "compute loss...\n",
            "(array([9191.30732692]), array([22525.99567574]))\n",
            "120 \\  200\n",
            "compute loss...\n",
            "(array([9191.28809395]), array([22525.96977352]))\n",
            "130 \\  200\n",
            "compute loss...\n",
            "(array([9191.28138786]), array([22525.96074201]))\n",
            "140 \\  200\n",
            "compute loss...\n",
            "(array([9191.27904959]), array([22525.95759292]))\n",
            "150 \\  200\n",
            "compute loss...\n",
            "(array([9191.27823429]), array([22525.9564949]))\n",
            "160 \\  200\n",
            "compute loss...\n",
            "(array([9191.27795001]), array([22525.95611205]))\n",
            "170 \\  200\n",
            "compute loss...\n",
            "(array([9191.27785089]), array([22525.95597855]))\n",
            "180 \\  200\n",
            "compute loss...\n",
            "(array([9191.27781633]), array([22525.95593201]))\n",
            "190 \\  200\n",
            "compute loss...\n",
            "(array([9191.27780427]), array([22525.95591578]))\n",
            "Predicted rating for user 133 and movie 76 : [4.37240281]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the squared error\n",
        "squared_error = (rating_prediction - user_133_ratings) ** 2\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(squared_error)\n",
        "\n",
        "print(\"RMSE for the Integrated Model for a User ID 133:\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEsP0MV8nnUy",
        "outputId": "4c58fc1d-9115-4b73-91f5-fc9fdc90495c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE for the Integrated Model for a User: [0.37240281]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 45\n",
        "movie_id = 100\n",
        "\n",
        "# Calculate the rating prediction for the given user and movie\n",
        "rating_prediction = predict_r_ui_integrated(mat, user_id, movie_id, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "print(\"Predicted rating for user\", user_id, \"and movie\", movie_id, \":\", rating_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS7OQ3Xlh1fR",
        "outputId": "21a0f0ac-2b4a-4588-d658-921eb3576999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 45 and movie 100 : [3.46822214]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "TG6AhQvCh6U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt\n",
        "from time import time\n",
        "\n",
        "def predict_r_ui_newmodelwo(mat, u, i, mu, bu, bi, Rk_iu, wij, baseline_bu, baseline_bi):\n",
        "    buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "    Rk_iu_sum = np.multiply((mat[u, Rk_iu] - buj), wij[i][Rk_iu]).sum()\n",
        "    return mu + bu[u] + bi[0, i] + Rk_iu_sum / sqrt(len(Rk_iu))\n",
        "\n",
        "def compute_e_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, baseline_bu, baseline_bi):\n",
        "    return mat[u, i] - predict_r_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, baseline_bu, baseline_bi)\n",
        "\n",
        "def compute_loss(mat, mu, bu, bi, Rk_iu, wij, baseline_bu, baseline_bi, l_reg=0.002):\n",
        "    loss = 0\n",
        "    loss_reg = 0\n",
        "    cx = mat.tocoo()\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        r_ui_pred = predict_r_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, baseline_bu, baseline_bi)\n",
        "        Rk_iu_sum = (wij[i][Rk_iu] ** 2).sum()\n",
        "        loss += (mat[u, i] - r_ui_pred) ** 2\n",
        "        loss_reg += l_reg * ((bu ** 2).sum() + (bi ** 2).sum() + Rk_iu_sum)\n",
        "\n",
        "    return loss, loss+loss_reg\n",
        "\n",
        "def correlation_based_neighbourhood_model_without_implicit(mat, mat_file, l_reg=0.002, gamma=0.005, k=250):\n",
        "    # subsample the matrix to make computation faster\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "\n",
        "    #baseline_bu, baseline_bi = baseline_estimator(mat)\n",
        "    # We should call baseline_estimator but we can init at random for test\n",
        "    baseline_bu, baseline_bi = np.random.rand(no_users, 1)  * 2 - 1, np.random.rand(1, no_movies) * 2 - 1\n",
        "\n",
        "    bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "    # Init parameters\n",
        "    bu = np.random.rand(no_users, 1)  * 2 - 1\n",
        "    bi = np.random.rand(1, no_movies) * 2 - 1\n",
        "    wij = np.random.rand(no_movies, no_movies) * 2 - 1\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "\n",
        "    # Compute similarity matrix\n",
        "    N = sparse.csr_matrix(mat).copy()\n",
        "    N.data[:] = 1\n",
        "    S = sparse.csr_matrix.dot(N.T, N)\n",
        "    S.data[:] = S.data[:] / (S.data[:] + l_reg2)\n",
        "    S = S * compute_sparse_correlation_matrix(mat)\n",
        "\n",
        "    # Train\n",
        "    print(\"Train...\")\n",
        "    n_iter = 200\n",
        "    cx = mat.tocoo()\n",
        "    for it in range(n_iter):\n",
        "        t0 = time()\n",
        "        for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "            Rk_iu = np.flip(np.argsort(S[i,].toarray()))[:k].ravel()\n",
        "            e_ui = compute_e_ui(mat, u, i, mu, bu, bi, Rk_iu, wij, baseline_bu, baseline_bi)\n",
        "\n",
        "            bu[u] += gamma * (e_ui - l_reg * bu[u])\n",
        "            bi[0, i] += gamma * (e_ui - l_reg * bi[0, i])\n",
        "\n",
        "            buj = mu + baseline_bu[u] + baseline_bi[0, Rk_iu]\n",
        "            wij[i][Rk_iu] += gamma * ( 1 / sqrt(len(Rk_iu)) * e_ui * (mat[u, Rk_iu].toarray().ravel() - buj) - l_reg * wij[i][Rk_iu] )\n",
        "        gamma *= 0.99\n",
        "\n",
        "        if it % 10 == 0:\n",
        "          t1 = time()\n",
        "          print(it, \"\\ \", n_iter, \"(%.2g sec)\" % (t1 - t0))\n",
        "          print(\"compute loss...\")\n",
        "          print(compute_loss(mat, mu, bu, bi, Rk_iu, wij, baseline_bu, baseline_bi, l_reg=l_reg))\n",
        "\n",
        "    return bu, bi, wij\n",
        "\n",
        "\n",
        "\n",
        "# Function to calculate RMSE\n",
        "def calculate_rmse(actual_ratings, predicted_ratings):\n",
        "    # Flatten the actual and predicted ratings matrices\n",
        "    actual = actual_ratings.data\n",
        "    predicted = predicted_ratings.data\n",
        "\n",
        "    # Calculate the squared error\n",
        "    squared_error = np.square(actual - predicted)\n",
        "\n",
        "    # Calculate the mean squared error\n",
        "    mean_squared_error = np.mean(squared_error)\n",
        "\n",
        "    # Calculate the RMSE\n",
        "    rmse = sqrt(mean_squared_error)\n",
        "    return rmse\n",
        "\n",
        "# Load the Netflix dataset\n",
        "mat_file = path + \"/T.mat\"\n",
        "mat = io.loadmat(mat_file)['X']\n",
        "# Initialize an empty list to store RMSE values\n",
        "rmse_values_corngbr = []\n",
        "rmse_values_newmodel = []\n",
        "rmse_values_wgtngbr = []\n",
        "rmse_values_newmodelwo = []\n",
        "# Iterate over different values of k\n",
        "for k in range(250, 8000):\n",
        "    # Calling all the correlation-based neighborhood models function\n",
        "    # Training and predicting the correlation based neighbourhood model with the current number of k value\n",
        "    predicted_ratings_corngbr = correlation_based_neighbourhood_model(mat, mat_file,l_reg2=100.0, k=k)\n",
        "    # Training the correlation based implicit feedback neighbourhood model with the current number of k value\n",
        "    bu, bi, wij, cij = correlation_based_implicit_neighbourhood_model(mat,mat_file, k=k)\n",
        "    # Predicting ratings using the trained model\n",
        "    predicted_ratings_newmodel = predict_r_ui_newmodel(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi)\n",
        "    # Training the correlation based without implicit feedback neighbourhood model with the current number of k value\n",
        "    bu, bi, wij = correlation_based_neighbourhood_model_without_implicit(mat, mat_file, k=k)\n",
        "    # Predicting ratings using the trained model\n",
        "    predicted_ratings_newmodelwo = predict_r_ui_newmodelwo(mat, u, i, mu, bu, bi, Rk_iu, wij, baseline_bu, baseline_bi)\n",
        "    # Training the correlation based weighted neighbourhood model with the current number of k value\n",
        "    bu, bi, theta_ui = correlation_based_neighbourhood_model_weighted(mat, mat_file, k=k)\n",
        "    # Predicting ratings using the trained model\n",
        "    predicted_ratings_wgtngbr = predict_r_ui_wgtngbr(mat, u, i, mu, bu, bi, Sk_iu, theta_ui, baseline_bu, baseline_bi)\n",
        "    # Calculate the RMSE and append it to the list\n",
        "    rmse_1 = calculate_rmse(mat, predicted_ratings_corngbr)\n",
        "    rmse_values_corngbr.append(rmse_1)\n",
        "    rmse_2 = calculate_rmse(mat, predicted_ratings_newmodel)\n",
        "    rmse_values_newmodel.append(rmse_2)\n",
        "    rmse_3 = calculate_rmse(mat, predicted_ratings_newmodelwo)\n",
        "    rmse_values_newmodelwo.append(rmse_3)\n",
        "    rmse_4 = calculate_rmse(mat, predicted_ratings_wgtngbr)\n",
        "    rmse_values_wgtngbr.append(rmse_4)\n",
        "\n",
        "    plt.plot(k, rmse_new_model, label='New Model')\n",
        "    plt.plot(k, rmse_new_model_wo, label='New Model w/o Implicit WgtNgbr')\n",
        "    plt.plot(k, rmse_corngbr, label='CorNgbr')\n",
        "    plt.plot(k, rmse_wgtngbr, label='WgtNgbr')\n",
        "\n",
        "# Set labels\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('RMSE')\n",
        "\n",
        "# Set title\n",
        "plt.title('RMSE vs k')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Z1cogFMnFuWI",
        "outputId": "d4c644cf-4248-44c0-aa1f-27da50c18ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##SVD and Evaluation of all the Factorization Methods\n",
        "import numpy as np\n",
        "from scipy import io, sparse\n",
        "from math import sqrt\n",
        "\n",
        "def predict_r_ui_svd(mat, u, i, mu, bu, bi, qi, pu, N_u, yj):\n",
        "    N_u_sum = yj[N_u].sum(0)\n",
        "    return mu + bu[u] + bi[0, i] + np.dot(qi[i], (pu[u] + N_u_sum / sqrt(len(N_u))))\n",
        "\n",
        "def compute_e_ui_svd(mat, u, i, mu, bu, bi, qi, pu, N_u, yj):\n",
        "    return mat[u, i] - predict_r_ui_svd(mat, u, i, mu, bu, bi, qi, pu, N_u, yj)\n",
        "\n",
        "def compute_loss_svd(mat, mu, bu, bi, qi, pu, N_u, yj, l_reg6=0.005, l_reg7=0.015):\n",
        "    loss = 0\n",
        "    loss_reg = 0\n",
        "    cx = mat.tocoo()\n",
        "    for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "        r_ui_pred = predict_r_ui_svd(mat, u, i, mu, bu, bi, qi, pu, N_u, yj)\n",
        "        loss += (mat[u, i] - r_ui_pred) ** 2\n",
        "        loss_reg += l_reg6 * ((bu ** 2).sum() + (bi ** 2).sum())\n",
        "        loss_reg += l_reg7 * ((qi[i]**2).sum() + (pu[u]**2).sum() + (yj[N_u]**2).sum())\n",
        "\n",
        "    return loss, loss+loss_reg\n",
        "\n",
        "def svd_model_function(mat, mat_file, gamma1=0.007, gamma2=0.007, l_reg6=0.005, l_reg7=0.015, f=50):\n",
        "    mat = mat[0:mat.shape[0]//128, 0:mat.shape[1]//128]\n",
        "    mat = mat[mat.getnnz(1)>0][:, mat.getnnz(0)>0]\n",
        "\n",
        "    print(mat.shape)\n",
        "    no_users = mat.shape[0]\n",
        "    no_movies = mat.shape[1]\n",
        "\n",
        "    bu_index, bi_index = pre_processing(mat, mat_file)\n",
        "\n",
        "    bu = np.random.rand(no_users, 1)  * 2 - 1\n",
        "    bi = np.random.rand(1, no_movies) * 2 - 1\n",
        "    qi = np.random.rand(no_movies, f) * 2 - 1\n",
        "    pu = np.random.rand(no_users, f) * 2 - 1\n",
        "    yj = np.random.rand(no_movies, f) * 2 - 1\n",
        "\n",
        "    mu = mat.data[:].mean()\n",
        "\n",
        "    print(\"Train...\")\n",
        "    n_iter = 200\n",
        "    cx = mat.tocoo()\n",
        "    for it in range(n_iter):\n",
        "        for u,i,v in zip(cx.row, cx.col, cx.data):\n",
        "            N_u = bi_index[u]\n",
        "            e_ui = compute_e_ui_svd(mat, u, i, mu, bu, bi, qi, pu, N_u, yj)\n",
        "\n",
        "            bu[u] += gamma1 * (e_ui - l_reg6 * bu[u])\n",
        "            bi[0, i] += gamma1 * (e_ui - l_reg6 * bi[0, i])\n",
        "            qi[i] += gamma2 * (e_ui * (pu[u] + 1 / sqrt(len(N_u)) * yj[N_u].sum(0)) - l_reg7 * qi[i])\n",
        "            pu[u] += gamma2 * (e_ui * qi[i] - l_reg7 * pu[u])\n",
        "            yj[N_u] += gamma2 * (e_ui * 1/ sqrt(len(N_u)) * qi[i] - l_reg7 * yj[N_u])\n",
        "        gamma1 *= 0.9\n",
        "        gamma2 *= 0.9\n",
        "\n",
        "        if it % 10 == 0:\n",
        "          print(it, \"\\ \", n_iter)\n",
        "          print(\"compute loss...\")\n",
        "          print(compute_loss_svd(mat, mu, bu, bi, qi, pu, N_u, yj, l_reg6=l_reg6, l_reg7=l_reg7))\n",
        "\n",
        "    return bu, bi, qi, pu, yj\n",
        "\n",
        "\n",
        "\n",
        "mat_file = path + \"/T.mat\"\n",
        "mat = io.loadmat(mat_file)['X']\n",
        "\n",
        "# Initialize an empty list to store RMSE values\n",
        "rmse_values_svdpp = []\n",
        "rmse_values_svd = []\n",
        "rmse_values_integrated = []\n",
        "# Iterate over different values of factors parameter (10 to 120)\n",
        "for factors in range(10, 121):\n",
        "    # Training the SVD++ model with the current number of factors\n",
        "    bu, bi, qi, pu, yj = svd_more_more(mat, mat_file, f=factors)\n",
        "    # Predicting ratings using the trained model\n",
        "    predicted_ratings_svdpp = predict_r_ui_svd_more_more(mat, u, i, mu, bu, bi, qi, pu, N_u, yj)\n",
        "    # Training the integrated model with the current number of factors\n",
        "    bu, bi, qi, pu, yj, wij, cij = integrated_model(mat, mat_file, f=factors)\n",
        "    # Predicting ratings using the trained model\n",
        "    predicted_ratings_integrated =  predict_r_ui_integrated(mat, u, i, mu, bu, bi, Rk_iu, wij, Nk_iu, cij, baseline_bu, baseline_bi, qi, pu, N_u, yj)\n",
        "    # Training the SVD model with the current number of factors\n",
        "    bu, bi, qi, pu, yj = svd_model_function(mat, mat_file, f=factors)\n",
        "    # Predicting ratings using the trained model\n",
        "    predicted_ratings_svd = predict_r_ui_svd(mat, u, i, mu, bu, bi, qi, pu, N_u, yj)\n",
        "    # Calculate the RMSE and append it to the list\n",
        "    rmse_1 = calculate_rmse(mat, predicted_ratings_svdpp)\n",
        "    rmse_values_svdpp.append(rmse_1)\n",
        "    rmse_2 = calculate_rmse(mat, predicted_ratings_integrated)\n",
        "    rmse_values_integrated.append(rmse_2)\n",
        "    rmse_3 = calculate_rmse(mat, predicted_ratings_svd)\n",
        "    rmse_values_svd.append(rmse_3)\n",
        "\n",
        "# Plot RMSE values against the factors parameter\n",
        "plt.plot(range(10, 121), rmse_values_svd, label='SVD')\n",
        "plt.plot(range(10, 121), rmse_values_svdpp, label='SVD++')\n",
        "plt.plot(range(10, 121), rmse_values_integrated, label='Integrated Model')\n",
        "plt.xlabel('Number of Factors')\n",
        "plt.ylabel('RMSE')\n",
        "plt.title('RMSE vs Number of Factors')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ldyFtmDlbS2F",
        "outputId": "384370c5-2d5d-40f5-86ad-a5666b22aec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}